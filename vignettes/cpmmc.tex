\documentclass{article}

\usepackage{amsmath, amsthm, amssymb}
\usepackage[round]{natbib}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother
\newcommand{\INDSTATE}[1][1]{\State\hspace{#1\algorithmicindent}}


% The line below tells R to use knitr on this.
%\VignetteEngine{knitr::knitr}

\title{An R Implementation for Correlated Pseudo Marginal Monte Carlo Methods}
\author{James Thornton \and Yuxi Jiang}

\usepackage{Sweave}
\begin{document}
\input{cpmmc-concordance}


\maketitle

\begin{abstract}
This document briefly summarises the statistical methodology underlying the \texttt{cpmmc} package, located at \url{https://github.com/JTT94/cpmmc}. In particular, this paper looks at the Correlated Pseudo Marginal Markov Chain theory introduced by [] and implementation to the random effect model.
\end{abstract}

\section{Introduction}

The Metropolis-Hastings (MH) [] algorithm is a particular Markov Chain Monte Carlo (MCMC) procedure used to sample asymptotically from a target distribution, $\pi$ in order to compute expectations with respect to the target distribution. This and similar MCMC procedures are often employed when it is difficult to sample $ \pi$ directly. The outline of MH is that one builds a markov chain with states $ \theta_t; t \in \mathbb{N}$, and stationary distribution $\pi$, coinciding with the desired target distribution. At each time, $ t $ , the state is updated stochastically via an accept/ reject probability on a proposal state, $\theta^\prime$, generated from some transitional kernel, $K$ with density $q$. The acceptance probability is defined as  $ \alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                \pi(\theta^\prime) q(\theta^\prime, \theta_{t-1})}
                {\pi(\theta_{t-1}) q(\theta_{t-1}, \theta^\prime)}
\right\} $. Provided certain ergodic conditions hold [], the average of accepted states in the generated Markov Chain will approach the desired expectation with respect to $\pi$. \\

In a Bayesian context, MH is often used to sample from a posterior distribution of some parameter of interest. Given observations $y_{1:t}$, and parameter of interest, $\theta$, with prior distribution $p$ $\theta \sim p$, the target distribution will be of form $\pi (\theta) = p(\theta ¦ y_{1:t} \propto p(y|\theta) p(\theta)$.\\

In order to implement MH for Bayesian inference, one would need to be able to evaluate $p(y|\theta) p(\theta)$ in order to perform the accept/ reject step in building the Markov chain. For many applications such as with latent variable models, the likelihood , $ p(y ¦ \theta)$, is often intractable thus making MH difficult to implement. \\

The pseudo-marginal (PM) algorithm follows the same procedure as the idealised MH, however introduces an estimator for the intractable likelihood, subject to certain conditions, to replace the true likelihood ratio required for the acceptance probability in the MH algorithm. This reduces the requirement of being able to compute likelihood $p(y|\theta)$, to only being required to be able to compute a non-negative, unbiased, unnormalised Monte Carlo estimate of this likelihood. \\

The correlated pseudo-marginal (CPM) algorithm is a development of the PM algorithm and shall be the focus of this document. The CPM correlates the estimators for the likelihood to reduce the variance of the resulting likelihood ratio in order to improve efficency in implementing the scheme. In [], correlated auxiliary variables are introduced in the calculation of the likelihood estimate to encourage correlation in the estimates. The main contributions of [], in addition to introducing this concept, are: providing theoretical results on the benefits, guidance on tuning parameters and applications in state space and random effect models, using correlated particle filter and importance sampling estimates respectively. This document shall however focus on the random effect model and a simulation study to demonstrate some properties empirically.

  \section{Methodology}
Let $p(y|\theta)$ denote the likelihood for the $T$ observations $y_{1:T}$, and let $p(\theta)$ be the prior density for the parameter $\theta \in \Theta \subseteq \mathbb{R}^{d}$. The Bayesian posterior density of interest can be written as $\pi (\theta) \propto p(y|\theta) p(\theta)$. To further abuse notation, denote $x \sim p$ to be that value x is a realised random variable sampled from distribution with density $p$.\\

\subsection{Metropolis-Hastings}
In a Bayesian setting, the MH algorithm is as detailed below, and the acceptance probability can be rewritten from $\alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                \pi(\theta^\prime) q(\theta^\prime, \theta_{t-1})}
                {\pi(\theta_{t-1}) q(\theta_{t-1}, \theta^\prime)}\right\}$ to
 $ \alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                p(y_{1:T}| \theta^\prime) q(\theta^\prime, \theta_{t-1})p(\theta^\prime)}
                {p(y_{1:T}| \theta_{t-1}) q(\theta_{t-1}, \theta^\prime)p(\theta_{t-1})}
\right\} $.

\begin{algorithm}[H]
\caption{Idealised Metropolis Hastings}\label{euclid}
\begin{algorithmic}[1]
\BState  $\text{Initialise } \theta_0 :$ \newline
\indent \text{Sample from prior} \hspace{\algorithmicindent} $\theta_0 \sim p$
\BState  $\text{At each iteration } t>0:$
\State \hspace{\algorithmicindent} $\text{Sample proposal: }$
$\theta^\prime \sim q(\theta_{t-1}, \cdot)$
\State \hspace{\algorithmicindent} $\text{Calculate accept/ reject probability: } \alpha_E(\theta_{t-1}, \theta^\prime):$ \newline
\centerline{
 $ \alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                p(y_{1:T}| \theta^\prime) q(\theta^\prime, \theta_{t-1})p(\theta^\prime)}
                {p(y_{1:T}| \theta_{t-1}) q(\theta_{t-1}, \theta^\prime)p(\theta_{t-1})}
\right\} $} \newline
\State \hspace{\algorithmicindent} $\text{With probabiliy: } \alpha_E(\theta_{t-1}, \theta^\prime)$ \newline \centerline{$\text{Set } \theta_t \gets \theta^\prime \text{ else } \theta_t \gets \theta_{t-1} $}
\end{algorithmic}
\end{algorithm}


\subsection{Correlated Pseudo-Marginal Algorithm}
To target $\pi$, CPM first augments the state from $\theta$ to $(\theta, U)$, with joint density $\bar{\pi}$. By simulating a Markov chain to target $\bar{\pi}$, one can record the $\theta$ values in order to target $\pi$. Given that $\hat{p} (y_{1:T} | \theta, U)$ is unbiased, we have that $\pi(\theta)$ is a marginal density of $\bar{\pi} (\theta, u)$, as $\int \bar{\pi}(\theta,u)du = \pi(\theta)$. \\

\centerline{$\bar{\pi}(\theta, u) = \pi(\theta)m(u)\frac{\hat{p}(y_{1:T}| \theta, u)}{p(y_{1:T}| \theta)}$}.

Assumptions:
\begin{itemize}
 \item $\hat{p}(y_{1:T}| \theta, U)$ is a non-negative, unbiased estimator of likelihood $p(y_{1:T}| \theta)$
 \item $U \sim m$
 \item $K$ is a transition kernel admitting an m-reversible Markov chain \newline
\centerline{$ m(u)K(u,u^\prime) = m(u^\prime)K(u^\prime, u)$} \newline
\end{itemize}



The Correlated Pseudo Marginal algorithm, detailed below, uses the above assumptions and the Metropolis Hastings algorithm to target $\bar{\pi}$ with a choice of $K$ to induce correlated $U$ proposals. This framework allows for running MH without having to compute $p(y_{1:T}| \theta)$. The primary difference to the idealised MH algorithm is swapping the likelihood ratio, $\frac{ p(y_{1:T}| \theta, U^\prime)}{ p(y_{1:T}| \theta, U)}$, with its estimator $\frac{ \hat{p}(y_{1:T}| \theta, U^\prime)}{ \hat{p}(y_{1:T}| \theta, U)}$ in the acceptance probability at each iteration. \\

Informally, the intuition behind the CPM, and in particular the correlation aspect, is as follows. Providing $\hat{p}(y_{1:T}| \cdot, \cdot)$ as a function of $(\theta, U)$ is sufficiently "nice" and $\theta$ is close to $\theta^\prime$, correlation amongst $U$ and $U^\prime$ will induce correlation amongst $\hat{p}(y_{1:T}| \theta, U)$ and $\hat{p}(y_{1:T}| \theta^\prime, U^\prime)$. This correlation lowers the variance of the ratio seen in the acceptance probability, $\frac{ \hat{p}(y_{1:T}| \theta, U^\prime)}{ \hat{p}(y_{1:T}| \theta, U)}$. Hence, the algorithm will be "more similar" to the idealised MH algorithm, and reduce the inefficiency introduced by taking using likelihood estimates rather than computing exact values of the likelihood.



\begin{algorithm}
\caption{Correlated Pseudo Marginal Algorithm}\label{euclid}
\begin{algorithmic}[1]
\BState  $\text{Initialise }  :$ \newline
\indent \hspace{\algorithmicindent} $\theta_0 \sim p_\theta$ \newline
\indent  \hspace{\algorithmicindent} $U_0 \sim p_U$
\BState  $\text{At each iteration } t>0:$
\State \hspace{\algorithmicindent} $\text{Sample proposal: }$
$\theta^\prime \sim q(\theta_{t-1}, \cdot)$
\State \hspace{\algorithmicindent} $\text{Sample auxiliary variables: }$
$ \epsilon \sim \mathcal{N}(0_M, I_M)$ \newline
\indent \text{Set } U^\prime = \rho U_{t-1} + \sqrt{1-\rho^2} \epsilon$
\State \hspace{\algorithmicindent} $\text{Compute estimator } \hat{p}(y_{1:T}| \theta^\prime, U^\prime) \text{ of } p(y_{1:T}| \theta^\prime, U^\prime)$
\State \hspace{\algorithmicindent} $\text{Calculate accept/ reject probability: } \alpha_E(\theta_{t-1}, \theta^\prime):$ \newline
\centerline{
 $ \alpha_E\{(\theta_{t-1}, U_{t-1}), (\theta^\prime, U^\prime)\} = min\left\{1,  \frac{
                \hat{p}(y_{1:T}| \theta^\prime, U^\prime) q(\theta^\prime, \theta_{t-1})p(\theta^\prime)}
                {\hat{p}(y_{1:T}| \theta_{t-1}, U_{t-1}) q(\theta_{t-1}, \theta^\prime)p(\theta_{t-1})}
\right\} $} \newline
\State \hspace{\algorithmicindent} $\text{With probabiliy: } \alpha_E\{(\theta_{t-1}, U_{t-1}), (\theta^\prime, U^\prime)\}$ \newline
\centerline{$\text{Set } (\theta_t, U_t) \gets (\theta^\prime, U^\prime) \text{ else } (\theta_t, U_t) \gets (\theta_{t-1}, U_{t-1}) $}
\end{algorithmic}
\end{algorithm}















    \subsection{Random Effect Model}



    \subsection{Discussion}
    -- Theory weak points
    -- Implementation weak points. inefficiencies



  \section{Application}

    \subsection{Simulation Study}

  \section{Conclusion}



%\texttt{align} environment (in the \texttt{amsmath} package) for displayed equations:
%\begin{align*}
% lose the *'s if you want equation numbers
%f(x) &= x^3 - x - 1\\
%g(y) &= y^4 + 2y
%\end{align*}
%You can cite in two ways using the \texttt{natbib} package:
%\citep{articlekey}
%and
%\citet{articlekey}.

  % now generate the bibliography from file mybib.bib
  \bibliographystyle{plainnat}
  \bibliography{mybib}


  \end{document}
