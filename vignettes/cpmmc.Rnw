\documentclass{article}

\usepackage{amsmath, amsthm, amssymb}
\usepackage[round]{natbib}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother
\newcommand{\INDSTATE}[1][1]{\State\hspace{#1\algorithmicindent}}

\newtheorem{theorem}{Theorem}

% The line below tells R to use knitr on this.
%\VignetteEngine{knitr::knitr}

\title{An R Implementation for Correlated Pseudo Marginal Monte Carlo Methods}
\author{James Thornton \and Yuxi Jiang}

\begin{document}
\SweaveOpts{concordance=TRUE}


\maketitle

\begin{abstract}
This document briefly summarises the statistical methodology underlying the \texttt{cpmmc} package, located at \url{https://github.com/JTT94/cpmmc}. In particular, this paper looks at the Correlated Pseudo Marginal Markov Chain theory introduced by \cite{cpmmDeligiannidis2015} and application to the random effects model.
\end{abstract}

\section{Background}

The Metropolis-Hastings (MH) algorithm, detailed fully by \cite{roberts2004}, is a particular Markov Chain Monte Carlo (MCMC) procedure used to sample asymptotically from a target distribution, $\pi$, in order to compute expectations with respect to the target distribution. This and similar MCMC procedures are often employed when it is difficult to sample from $\pi$ directly. The outline of MH is that one builds a markov chain with states $ \theta_t $; $ t \in \mathbb{N}$, and stationary distribution $\pi$, coinciding with the desired target distribution. At each time $ t $ , the state is updated stochastically via an acceptance/rejection probability on a proposal state, $\theta^\prime$, generated from some transition kernel, $K$ with density $q$. The acceptance probability is defined as  $ \alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                \pi(\theta^\prime) q(\theta^\prime, \theta_{t-1})}
                {\pi(\theta_{t-1}) q(\theta_{t-1}, \theta^\prime)}
\right\} $. Provided certain ergodic conditions given by \cite{roberts2004} hold, the arithmetic average of accepted states in the generated Markov Chain will approach the desired expectation with respect to $\pi$. \\

In a Bayesian context, MH is often used to sample from a posterior distribution of some parameter of interest, $\theta$. Given observations $y_{1:t}$, and parameter of interest with prior distribution $p$, the target distribution will be of the form $\pi (\theta) = p(\theta | y_{1:t} ) \propto p(y|\theta) p(\theta)$.\\

In order to implement MH for Bayesian inference, one would need to be able to evaluate $p(y|\theta) p(\theta)$ in order to perform the accept/reject step in building the Markov chain. For many applications, such as with latent variable models, the likelihood, $ p(y | \theta)$, is often intractable thus making MH difficult to implement. \\

The pseudo-marginal (PM) algorithm follows the same procedure as the idealised MH, however, it introduces an estimator for the intractable likelihood to replace the true likelihood ratio required for the acceptance probability. This reduces the requirement of being able to compute likelihood $p(y|\theta)$, to only being required to be able to compute a non-negative, unbiased, unnormalised Monte Carlo estimate of this likelihood. \\

The correlated pseudo-marginal (CPM) algorithm is a development of the PM algorithm and shall be the focus of this document. The CPM correlates the estimators for the likelihood to reduce the variance of the resulting likelihood ratio, in order to improve efficiency in implementing the scheme. In \cite{cpmmDeligiannidis2015}, correlated auxiliary variables are introduced in the calculation of the likelihood estimate to encourage correlation in the estimates.\\

The main contributions of \cite{cpmmDeligiannidis2015}, in addition to introducing this correlation approach, are: providing theoretical results on the benefits, guidance on tuning parameters and demonstrated applications in state space and random effect models. This document shall focus on the high-level CPM theory, random effect model and a simulation study to demonstrate some properties empirically.

\section{Methodology}
Let $p(y_{1:T}|\theta)$ denote the likelihood for the $T$ observations $y_{1:T}$, and let $p(\theta)$ be the prior density for the parameter $\theta \in \Theta \subseteq \mathbb{R}^{d}$. The Bayesian posterior density of interest can be written as $\pi (\theta) \propto p(y_{1:T}|\theta) p(\theta)$. To further abuse notation, let $x \sim p$ denote sampling realisation x from the distribution with density $p$.\\

\subsection{Metropolis-Hastings}
In a Bayesian setting, the MH algorithm is as detailed below, the acceptance probability have been rewritten from $\alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                \pi(\theta^\prime) q(\theta^\prime, \theta_{t-1})}
                {\pi(\theta_{t-1}) q(\theta_{t-1}, \theta^\prime)}\right\}$ to
 $ \alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                p(y_{1:T}| \theta^\prime) q(\theta^\prime, \theta_{t-1})p(\theta^\prime)}
                {p(y_{1:T}| \theta_{t-1}) q(\theta_{t-1}, \theta^\prime)p(\theta_{t-1})}
\right\} $ to emphasis the need to compute the exact likelihood.

\begin{algorithm}[H]
\caption{Idealised Metropolis Hastings}\label{euclid}
\begin{algorithmic}[1]
\BState  $\text{Initialise } \theta_0 :$ \newline
\indent \text{Sample from prior} \hspace{\algorithmicindent} $\theta_0 \sim p$
\BState  $\text{At each iteration } t>0:$
\State \hspace{\algorithmicindent} $\text{Sample proposal: }$
$\theta^\prime \sim q(\theta_{t-1}, \cdot)$
\State \hspace{\algorithmicindent} $\text{Calculate acceptance probability } \alpha_E(\theta_{t-1}, \theta^\prime):$ \newline
\centerline{
 $ \alpha_E(\theta_{t-1}, \theta^\prime) = min\left\{1,  \frac{
                p(y_{1:T}| \theta^\prime) q(\theta^\prime, \theta_{t-1})p(\theta^\prime)}
                {p(y_{1:T}| \theta_{t-1}) q(\theta_{t-1}, \theta^\prime)p(\theta_{t-1})}
\right\} $} \newline
\State \hspace{\algorithmicindent} $\text{With probabiliy: } \alpha_E(\theta_{t-1}, \theta^\prime)$ \newline \centerline{$\text{Set } \theta_t \gets \theta^\prime \text{ else } \theta_t \gets \theta_{t-1} $}
\end{algorithmic}
\end{algorithm}


\subsection{Correlated Pseudo-Marginal Algorithm}
To target $\pi$, the CPM first augments the state from $\theta$ to $(\theta, U)$, with joint density $\bar{\pi}$ given as
$$\bar{\pi}(\theta, u) = \pi(\theta)m(u)\frac{\hat{p}(y_{1:T}| \theta, u)}{p(y_{1:T}| \theta)}$$
By simulating a Markov chain to target $\bar{\pi}$, one can record only the $\theta$ values in order to target $\pi$. Given that $\hat{p} (y_{1:T} | \theta, U)$ is unbiased, we have that $\pi(\theta)$ is a marginal density of $\bar{\pi} (\theta, u)$, as $\int \bar{\pi}(\theta,u)du = \pi(\theta)$. \\

The Correlated Pseudo Marginal algorithm uses the following assumptions, as well as the Metropolis Hastings algorithm to target $\bar{\pi}$ with a choice of transition kernel $K$ to induce correlated $U$ proposals.
\begin{itemize}
 \item $\hat{p}(y_{1:T}| \theta, U)$ is a non-negative, unbiased estimator of likelihood $p(y_{1:T}| \theta)$
 \item $U \sim m$
 \item $K$ is a transition kernel admitting an m-reversible Markov chain $$ m(u)K(u,u^\prime) = m(u^\prime)K(u^\prime, u)$$
\end{itemize}


This framework allows for running MH without having to compute $p(y_{1:T}| \theta)$. The primary difference to the idealised MH algorithm is swapping the likelihood ratio, $\frac{ p(y_{1:T}| \theta, U^\prime)}{ p(y_{1:T}| \theta, U)}$, with its estimator $\frac{ \hat{p}(y_{1:T}| \theta, U^\prime)}{ \hat{p}(y_{1:T}| \theta, U)}$ in the acceptance probability at each iteration. \\

Informally, the intuition behind the CPM, and in particular the correlation aspect, is as follows. Providing $\hat{p}(y_{1:T}| \cdot, \cdot)$ as a function of $(\theta, U)$ is sufficiently "nice" and $\theta$ is close to $\theta^\prime$, correlation amongst $U$ and $U^\prime$ will induce correlation amongst $\hat{p}(y_{1:T}| \theta, U)$ and $\hat{p}(y_{1:T}| \theta^\prime, U^\prime)$. This correlation lowers the variance of the ratio seen in the acceptance probability, $\frac{ \hat{p}(y_{1:T}| \theta, U^\prime)}{ \hat{p}(y_{1:T}| \theta, U)}$. Hence, the algorithm will be "more similar" to the idealised MH algorithm, and reduce the inefficiency introduced by taking estimates rather than computing the exact values of the likelihood.


\begin{algorithm}[H]
\caption{Correlated Pseudo Marginal Algorithm}\label{euclid}
\begin{algorithmic}[1]
\BState  $\text{Initialise }  :$ \newline
\indent \hspace{\algorithmicindent} $\theta_0 \sim p_\theta$ \newline
\indent  \hspace{\algorithmicindent} $U_0 \sim p_U$
\BState  $\text{At each iteration } t>0:$
\State \hspace{\algorithmicindent} $\text{Sample proposal: }$
$\theta^\prime \sim q(\theta_{t-1}, \cdot)$
\State \hspace{\algorithmicindent} $\text{Sample auxiliary variables: }$
$ \epsilon \sim \mathcal{N}(0_M, I_M)$ \newline
\indent \text{Set } $U^\prime = \rho U_{t-1} + \sqrt{1-\rho^2} \epsilon$
\State \hspace{\algorithmicindent} $\text{Compute estimator } \hat{p}(y_{1:T}| \theta^\prime, U^\prime) \text{ of } p(y_{1:T}| \theta^\prime, U^\prime)$
\State \hspace{\algorithmicindent} $\text{Calculate acceptance probability: } \alpha_E(\theta_{t-1}, \theta^\prime):$ \newline
\centerline{
 $ \alpha_E\{(\theta_{t-1}, U_{t-1}), (\theta^\prime, U^\prime)\} = min\left\{1,  \frac{
                \hat{p}(y_{1:T}| \theta^\prime, U^\prime) q(\theta^\prime, \theta_{t-1})p(\theta^\prime)}
                {\hat{p}(y_{1:T}| \theta_{t-1}, U_{t-1}) q(\theta_{t-1}, \theta^\prime)p(\theta_{t-1})}
\right\} $} \newline
\State \hspace{\algorithmicindent} $\text{With probabiliy: } \alpha_E\{(\theta_{t-1}, U_{t-1}), (\theta^\prime, U^\prime)\}$ \newline
\centerline{$\text{Set } (\theta_t, U_t) \gets (\theta^\prime, U^\prime) \text{ else } (\theta_t, U_t) \gets (\theta_{t-1}, U_{t-1}) $}
\end{algorithmic}
\end{algorithm}


\subsection{Random Effect Model}

Define the model as follows:
\begin{align*}
x \sim& f_\theta(\cdot) \\
Y_t| X_t \sim& g_\theta(\cdot | X_t)
\end{align*}
where $t \in \mathbb{N}$ and $\{X_t; t>0\}$ are $\mathbb{R}^k$-valued latent variables and $\{Y_t; t>0\}$ are $\mathcal{Y}$-valued observations.\\

For observed data $Y_{1:T}=y_{1:T}$, the likelihood satisfies:
\begin{align*}
p(y_{1:T})=& \prod_{t=1}^{T} p(y_t|\theta) \\
p(y_t| \theta)=& \int g_\theta(y_t|x_t,\theta)f_\theta(x_t) dx_t
\end{align*}

If the integral for $p(y_t| \theta)$ is intractable, one can use importance sampling to form an unbiased estimator $\hat{p}(y_t| \theta)$, where $N$ is the number of proposal samples. The likelihood estimator and importance sampling weights are given as
\begin{align*}
\hat{p}(y_{1:T}| \theta, U) =& \prod_{t=1}^{T} \hat{p}(y_t|\theta, U_t) \\
\hat{p}(y_t| \theta, U_t)=& \frac{1}{N} \sum_{i=i}^N w(y_t, U_{t,i}; \theta \\
w(y_t, U_{t,i} =& \frac{g_\theta(y_t|X_{t,i})f_\theta(X_{t,i})}{q_\theta(X_{t,i}|y_t)}
\end{align*}
assuming that there exists a deterministic map $ \Xi: \mathbb{R}^p \times \Theta \rightarrow \mathbb{R}^k$ such that $X_{t,i} = \Xi(U_{t,i}, \theta) \sim q_\theta(\cdot|y_t)$ and $U_{t,i} \sim \mathcal{N}(0_p, I_p) $.

\subsection{Key Results on Parameter Tuning}

Other than introducing the approach, the primary theoretic contributions of \cite{cpmmDeligiannidis2015} are in specifying the distributions of the loglikelihood error, $Z_T(\theta)$, and loglikelihood error ratio, $R_T(\theta, \theta^\prime)$ under correlated $U$ proposals and under non-correlated for comparison of CPM with the PM algorithm.
\begin{align*}
Z_T(\theta) =& \log(\hat{p}(Y_{1:T}| \theta, U)) - \log(p(Y_{1:T}|\theta)) \\
R_T(\theta, \theta^\prime) =& \log \frac{\hat{p}(Y_{1:T}| \theta^\prime, U^\prime)}{\hat{p}(Y_{1:T}| \theta, U)} - \log \frac{p(Y_{1:T}| \theta^\prime,)}{p(Y_{1:T}| \theta)}
\end{align*}
The significance of these results lies in using them to inform choice of parameters $\rho$ and $N$ which controls the correlation and number of Monte Carlo samples in the unbiased estimator respectively. \\

In the interest of brevity, the theorems of \cite{cpmmDeligiannidis2015} which state that $Z_T(\theta)$ and $R_T(\theta, \theta^\prime)$ are asympototically normal are not repeated below. However, the key practical implications are that one should find $\beta>0, \psi>0$ and set the CPM parameters such that:
\begin{align*}
N_T =& \beta T ^{\frac{1}{2}} \\
\rho =& \exp(-\psi \beta T ^ {-\frac{1}{2}}) = \exp(-\psi \frac{N_T}{T})
\end{align*}

\cite{cpmmDeligiannidis2015} then provides a heuristic to find these parameters by minimizing a specific objective function, however it has been excluded from this document due to the involved nature.



\subsection{Discussion}
    -- Higher dimension, size of M =pTN \\
    -- Difficulties when estimator is not "nice" i.e. continuous \\
    -- Implementation weak points, inefficienciesm, have to loop through each data point and sample N for each point



  \section{Application}

  \subsection{Simulation Study}

  \section{Conclusion}


% \begin{theorem}
% Let $N_T = \beta T^\alpha$ with $\frac{1}{3} < \alpha \leq 1$ and $Y_i \overset{i.i.d.}{\sim} \mu$ \\
%
% 1) If $\mathbb{E}[\bar{w}(Y, U_{1,1}, \theta)^8] < \infty$ and $U \sim m$, then:\\
%
% \centerline{
% $T^{\frac{\alpha -1}{2}}Z_T{\theta} + \frac{1}{2}T^{\frac{1-\alpha}{2}}\beta^{-1}\gamma(\theta)^2 | \mathcal{Y}^T \Rightarrow \mathcal{N}(0, \beta^{-1}\gamma(\theta)^2)$} \newline
%
% 2) If $\mathbb{E}[\bar{w}(Y, U_{1,1}, \theta)^9] < \infty$ and $U \sim \bar{\pi}(\cdot, \theta)$, then:\\
%
% \centerline{
% $T^{\frac{\alpha -1}{2}}Z_T{\theta} - \frac{1}{2}T^{\frac{1-\alpha}{2}}\beta^{-1}\gamma(\theta)^2 | \mathcal{Y}^T \Rightarrow \mathcal{N}(0, \beta^{-1}\gamma(\theta)^2)$}\\
%
% \end{theorem}
%
% \begin{theorem}
% Let $\theta, \xi$ be fixed. Assume: \\
% 1) $\vartheta \mapsto \bar{w}(y_1, u_{1,1}; \vartheta)$ and $\vartheta \mapsto \mathbb{E}[\bar{w}(y_1, u_{1,1}; \vartheta)^9]$ are continuous at $\vartheta = \theta$ for any $ (y_1, u_{1,1} ) \in \mathbb(Y) \times \mathbb{R}^p$ \\
% 2) $\vartheta \mapsto \gamma(\vartheta)$ is continously differentiable at $\vartheta = \theta$ \\
% 3) $\mathbb{E}[\bar{w}(Y_1, U_{1,1}; \vartheta)^9] + \mathbb{E}[\gamma(Y_1;\vartheta)^4] < \infty$ \\
%
% For $N_T = \beta T^\alpha$ with $\frac{1}{3} < \alpha \leq 1$ and $Y_i \overset{i.i.d.}{\sim} \mu$, $U \sim \bar{\pi}(\cdot, \theta)$ and $U^\prime \sim m$ where $U$ and $U^\prime$ are independent: \\
%
% \centerline{
% $T^{\frac{\alpha -1}{2}}R_T(\theta, \theta + \xi / \sqrt{T}) + T^{\frac{1-\alpha}{2}}\beta^{-1}\gamma(\theta)^2 | \mathcal{Y}^T \Rightarrow \mathcal{N}(0, 2\beta^{-1}\gamma(\theta)^2)$}\\
%
% \end{theorem}
%
%
% Theorems 1 and 2 from the paper here for random effect model

%\texttt{align} environment (in the \texttt{amsmath} package) for displayed equations:
%\begin{align*}
% lose the *'s if you want equation numbers
%f(x) &= x^3 - x - 1\\
%g(y) &= y^4 + 2y
%\end{align*}
%You can cite in two ways using the \texttt{natbib} package:
%\citep{articlekey}
%and
%\citet{articlekey}.

  % now generate the bibliography from file mybib.bib
  \bibliographystyle{plainnat}
  \bibliography{mybib}


  \end{document}
